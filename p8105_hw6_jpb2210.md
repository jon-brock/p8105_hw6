Data Science - Homework \#6
================
Jon Brock - JPB2210

  - [Problem \#1](#problem-1)
  - [Problem \#2](#problem-2)
  - [Return of the Bonus Content](#return-of-the-bonus-content)

``` r
library(tidyverse)
library(modelr)
library(mgcv)
```

-----

## Problem \#1

###### (*45 points*)

##### *Working with linear models*

I reviewed each vector to determine what vector type each one should be
when imported. There is a majority of integer values, so the `.default`
value for non-specified vectors applies as such. I specified `babysex`,
`frace`, `malform`, and `mrace` as `<fct>` vectors; `gaweeks`, `ppbmi`,
and `smoken` are specified as `<dbl>` vectors. I will further
tidy–relevel and relabel–my specified `<fct>` vectors in subsequent
code.

``` r
bw_df <- read_csv("./data/birthweight.csv",
                  col_names = TRUE,
                  col_types = cols(
                      .default = col_integer(),
                      babysex = col_factor(),
                      frace = col_factor(),
                      gaweeks = col_double(),
                      malform = col_factor(),
                      mrace = col_factor(),
                      ppbmi = col_double(),
                      smoken = col_double()
                      )
                  )

bw_df
```

    ## # A tibble: 4,342 x 20
    ##    babysex bhead blength   bwt delwt fincome frace gaweeks malform menarche
    ##    <fct>   <int>   <int> <int> <int>   <int> <fct>   <dbl> <fct>      <int>
    ##  1 2          34      51  3629   177      35 1        39.9 0             13
    ##  2 1          34      48  3062   156      65 2        25.9 0             14
    ##  3 2          36      50  3345   148      85 1        39.9 0             12
    ##  4 1          34      52  3062   157      55 1        40   0             14
    ##  5 2          34      52  3374   156       5 1        41.6 0             13
    ##  6 1          33      52  3374   129      55 1        40.7 0             12
    ##  7 2          33      46  2523   126      96 2        40.3 0             14
    ##  8 2          33      49  2778   140       5 1        37.4 0             12
    ##  9 1          36      52  3515   146      85 1        40.3 0             11
    ## 10 1          33      50  3459   169      75 2        40.7 0             12
    ## # … with 4,332 more rows, and 10 more variables: mheight <int>,
    ## #   momage <int>, mrace <fct>, parity <int>, pnumlbw <int>, pnumsga <int>,
    ## #   ppbmi <dbl>, ppwt <int>, smoken <dbl>, wtgain <int>

It is rather tedious to check for `NA` values within individual vectors
one at a time. So, instead, I decided to check all vectors at once by
using a “soft-deprecated” `dplyr` function (`funs()`) to summarize all
of the `NA` observations within each vector in my data frame.

``` r
options(tibble.width = Inf)

bw_df %>% 
    select(everything()) %>% 
    summarize_all(funs(sum(is.na(.))))
```

    ## # A tibble: 1 x 20
    ##   babysex bhead blength   bwt delwt fincome frace gaweeks malform menarche
    ##     <int> <int>   <int> <int> <int>   <int> <int>   <int>   <int>    <int>
    ## 1       0     0       0     0     0       0     0       0       0        0
    ##   mheight momage mrace parity pnumlbw pnumsga ppbmi  ppwt smoken wtgain
    ##     <int>  <int> <int>  <int>   <int>   <int> <int> <int>  <int>  <int>
    ## 1       0      0     0      0       0       0     0     0      0      0

The output shows that we have `0` observations of `NA` in all of our
vectors. We’re good to go\!

``` r
bw_df <- 
    bw_df %>% 
    mutate(
        baby_sex = recode(babysex, "1" = "male", "2" = "female"),
        baby_head_cm = bhead,
        baby_length_cm = blength,
        baby_birthweight_grams = bwt,
        mother_weight_grams = delwt * 453.492,
        family_income = fincome,
        father_race = recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "p_rican", "8" = "other", "9" = "unknown"),
        gestation_age_wks = gaweeks,
        malformations_present = recode(malform, "0" = "absent", "1" = "present"),
        mother_menarche_age = menarche,
        mother_height_cm = mheight * 2.54,
        mother_delivery_age = momage,
        mother_race = recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "p_rican", "8" = "other"),
        number_prior_births = parity,
        number_prior_low_bwt_babies = pnumlbw,
        number_prior_small_ga_babies = pnumsga,
        mother_pre_pregnancy_bmi = ppbmi,
        mother_pre_pregnancy_weight_grams = ppwt * 453.492,
        avg_number_cigs_per_day = smoken,
        mother_pregnancy_weight_gain_grams = wtgain * 453.492) %>% 
    select(c(baby_sex:mother_pregnancy_weight_gain_grams))

# I am only printing the column names because otherwise the data output is excessive due to column name size
colnames(bw_df)
```

    ##  [1] "baby_sex"                          
    ##  [2] "baby_head_cm"                      
    ##  [3] "baby_length_cm"                    
    ##  [4] "baby_birthweight_grams"            
    ##  [5] "mother_weight_grams"               
    ##  [6] "family_income"                     
    ##  [7] "father_race"                       
    ##  [8] "gestation_age_wks"                 
    ##  [9] "malformations_present"             
    ## [10] "mother_menarche_age"               
    ## [11] "mother_height_cm"                  
    ## [12] "mother_delivery_age"               
    ## [13] "mother_race"                       
    ## [14] "number_prior_births"               
    ## [15] "number_prior_low_bwt_babies"       
    ## [16] "number_prior_small_ga_babies"      
    ## [17] "mother_pre_pregnancy_bmi"          
    ## [18] "mother_pre_pregnancy_weight_grams" 
    ## [19] "avg_number_cigs_per_day"           
    ## [20] "mother_pregnancy_weight_gain_grams"

We have successfully recoded and renamed all `20` of our variables, and
dropped the original `20` for lack of further need. It’s important to
note that variable measurements were incongruent in terms of scale –
both metric and imperial were used. To correct for this I made the
necessary conversions so that all measurements are metric (i.e., weight
= grams, height/length = centimeters).

-----

Now let’s fit a linear model with hypothesized predictor variables.
Based on all of the previous CUMC Epidemiology courses’ content, I
believe that gestational age (`gestation_age_wks`), mother’s weight
(`mother_weight_grams`), number of prior low-birthweight babies
(`number_prior_low_bwt_babies`), and average number of cigarettes smoked
per day (`avg_number_cigs_per_day`) are strong predictors of the
birthweight of a baby. Subsequently, we fit our linear model as such:

``` r
jon_fit <- lm(baby_birthweight_grams ~ 
                  gestation_age_wks +
                  mother_weight_grams +
                  number_prior_low_bwt_babies +
                  avg_number_cigs_per_day,
              data = bw_df)

broom::tidy(jon_fit) %>% 
    knitr::kable()
```

| term                        |      estimate |  std.error |  statistic |   p.value |
| :-------------------------- | ------------: | ---------: | ---------: | --------: |
| (Intercept)                 | \-145.8454947 | 91.7888378 | \-1.588924 | 0.1121504 |
| gestation\_age\_wks         |    62.5747139 |  2.1709484 |  28.823676 | 0.0000000 |
| mother\_weight\_grams       |     0.0124554 |  0.0006804 |  18.307006 | 0.0000000 |
| avg\_number\_cigs\_per\_day |   \-7.0170283 |  0.9184265 | \-7.640272 | 0.0000000 |

Now, let’s plot our `jon_fit` linear model’s predicted values against
its residuals to see how well our model fits the data.

``` r
predicted_vs_residuals_jon_fit <- 
    bw_df %>% 
    add_predictions(jon_fit) %>% 
    add_residuals(jon_fit) %>% 
    select(pred, resid)

predicted_vs_residuals_jon_fit  %>% 
    ggplot(aes(x = pred, y = resid)) +
    geom_point() +
    geom_hline(yintercept = 0, color = "red", size = 1, linetype = 2) +
    labs(
        title = "Versus Fits of jon_fit Linear Model",
        x = "Fitted Value (grams)",
        y = "Residual (grams)")
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/fitting residuals against predictions-1.png" style="display: block; margin: auto;" />

We can see that there is a large variance within the specified model, as
many points are far from the (dotted) prediction line. Let’s now compare
our specified model to two additional models:

1.  p8105\_fit\_1 = `baby_length_cm + gestation_age_wks` (main effects
    only)  
2.  p8105\_fit\_2 = `baby_head_cm * baby_length_cm * baby_sex` (main
    effects plus interactions between all predictors)

<!-- end list -->

``` r
p8105_fit_1 <- lm(baby_birthweight_grams ~ baby_length_cm + gestation_age_wks, data = bw_df)

broom::tidy(p8105_fit_1) %>% 
    knitr::kable()
```

| term                |     estimate | std.error |  statistic | p.value |
| :------------------ | -----------: | --------: | ---------: | ------: |
| (Intercept)         | \-4347.66707 | 97.958360 | \-44.38281 |       0 |
| baby\_length\_cm    |    128.55569 |  1.989891 |   64.60439 |       0 |
| gestation\_age\_wks |     27.04673 |  1.717930 |   15.74379 |       0 |

``` r
p8105_fit_2 <- lm(baby_birthweight_grams ~ baby_head_cm * baby_length_cm * baby_sex, data = bw_df)

broom::tidy(p8105_fit_2) %>% 
    knitr::kable()
```

| term                                          |      estimate |    std.error |   statistic |   p.value |
| :-------------------------------------------- | ------------: | -----------: | ----------: | --------: |
| (Intercept)                                   |  \-801.948671 | 1102.3077046 | \-0.7275180 | 0.4669480 |
| baby\_head\_cm                                |   \-16.597546 |   34.0916082 | \-0.4868514 | 0.6263883 |
| baby\_length\_cm                              |   \-21.645964 |   23.3720477 | \-0.9261475 | 0.3544209 |
| baby\_sexmale                                 | \-6374.868351 | 1677.7669213 | \-3.7996150 | 0.0001469 |
| baby\_head\_cm:baby\_length\_cm               |      3.324444 |    0.7125586 |   4.6655020 | 0.0000032 |
| baby\_head\_cm:baby\_sexmale                  |    198.393181 |   51.0916850 |   3.8830816 | 0.0001047 |
| baby\_length\_cm:baby\_sexmale                |    123.772887 |   35.1185360 |   3.5244319 | 0.0004288 |
| baby\_head\_cm:baby\_length\_cm:baby\_sexmale |    \-3.878053 |    1.0566296 | \-3.6702106 | 0.0002453 |

I don’t believe this is required (for this problem), but we can also
plot these two models’ predicted values against their corresponding
residuals to see how well their models fit their data.

``` r
predicted_vs_residuals_p8015_fit_1 <- 
    bw_df %>% 
    add_predictions(p8105_fit_1) %>% 
    add_residuals(p8105_fit_1) %>% 
    select(pred, resid)

predicted_vs_residuals_p8015_fit_1 %>% 
    ggplot(aes(x = pred, y = resid)) +
    geom_point() +
    geom_hline(yintercept = 0, color = "red", size = 1, linetype = 2) +
    labs(
        title = "Versus Fits of p8105_fit_1 Linear Model",
        x = "Fitted Value (grams)",
        y = "Residual (grams)")
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/fitting residuals against predictions (A)-1.png" style="display: block; margin: auto;" />

``` r
predicted_vs_residuals_p8015_fit_2 <- 
    bw_df %>% 
    add_predictions(p8105_fit_2) %>% 
    add_residuals(p8105_fit_2) %>% 
    select(pred, resid)

predicted_vs_residuals_p8015_fit_2 %>% 
    ggplot(aes(x = pred, y = resid)) +
    geom_point() +
    geom_hline(yintercept = 0, color = "red", size = 1, linetype = 2) +
    labs(
        title = "Versus Fits of p8105_fit_2 Linear Model",
        x = "Fitted Value (grams)",
        y = "Residual (grams)")
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/fitting residuals against predictions (B)-1.png" style="display: block; margin: auto;" />

Based on those plots, it appears as though the second model
(`p8105_fit_1`) has the least error variance. But let us use cross
validation methods in order to check all of our models for the best fit.
We start by producing 500 training/testing data splits of our original
data `bw_df`. \[Note: I chose `500` as the `n` because I was not sure
what number to select. It appeared to be a user-specified value.\]

``` r
cv_df <-
    crossv_mc(bw_df, 500)
```

Now, we will generate fitted models for each of the three linear models
specified, as well as generate the root mean squared error `RMSE` for
each of the fitted models.

``` r
cv_df <- 
    cv_df %>% 
    mutate(jon_model = map(train, ~jon_fit, data = .x),
           p8105_1_model = map(train, ~p8105_fit_1, data = .x),
           p8105_2_model = map(train, ~p8105_fit_2, data = .x)) %>% 
    mutate(rmse_jon = map2_dbl(jon_model, test, ~rmse(model = .x, data = .y)),
           rmse_p8105_1 = map2_dbl(p8105_1_model, test, ~rmse(model = .x, data =.y)),
           rmse_p8105_2 = map2_dbl(p8105_2_model, test, ~rmse(model = .x, data = .y)))
```

We can now plot out results to visually inspect which model has the best
fitting.

``` r
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
    geom_violin(fill = "tan1") +
    labs(
        title = "Cross Validation of Specified Models",
        x = "Model",
        y = "Root Mean Squared Error (RMSE)")
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/generate plot of model comparisons-1.png" style="display: block; margin: auto;" />

Even though our predicted vs. residuals plots indicated that `p8105_1`
had the least amount of error variance, we see from our cross validation
plot that the `p8105_2` model has the best `RMSE` and is the best fit.
Recall that this model has both our main effects, as well as the
interaction between all three predictors, included.

-----

## Problem \#2

###### (*35 points*)

##### *Bootstrapping*

This problem focuses on bootstrapping. First, we import a dataset from
NOAA that contains the `minimum` and `maximum` temperatures for Central
Park, NY from the time period 2017-01-10 through 2017-12-31.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_df
```

    ## # A tibble: 365 x 6
    ##    name           id          date        prcp  tmax  tmin
    ##    <chr>          <chr>       <date>     <dbl> <dbl> <dbl>
    ##  1 CentralPark_NY USW00094728 2017-01-01     0   8.9   4.4
    ##  2 CentralPark_NY USW00094728 2017-01-02    53   5     2.8
    ##  3 CentralPark_NY USW00094728 2017-01-03   147   6.1   3.9
    ##  4 CentralPark_NY USW00094728 2017-01-04     0  11.1   1.1
    ##  5 CentralPark_NY USW00094728 2017-01-05     0   1.1  -2.7
    ##  6 CentralPark_NY USW00094728 2017-01-06    13   0.6  -3.8
    ##  7 CentralPark_NY USW00094728 2017-01-07    81  -3.2  -6.6
    ##  8 CentralPark_NY USW00094728 2017-01-08     0  -3.8  -8.8
    ##  9 CentralPark_NY USW00094728 2017-01-09     0  -4.9  -9.9
    ## 10 CentralPark_NY USW00094728 2017-01-10     0   7.8  -6  
    ## # … with 355 more rows

Now we will generate 5000 bootstrap samples from the `weather_df` data
frame, and fit a simple linear regression with `tmax` as the response
and `tmin` as the predictor for each of the 5000 samples. We only want
to look at the distribution of the R-squared value, as well as the log
of the product of Beta0 and Beta1, so we will remove all other items in
the resulting data frame.

``` r
set.seed(90210) #See what I did there?

boot_strap <- 
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    tidy_models = map(models, broom::tidy),
    glance_models = map(models, broom::glance)) %>% 
  unnest(tidy_models, glance_models) %>% 
  select(.id, term, estimate, r.squared) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate) %>% 
  rename(
    beta_0 = `(Intercept)`,
    beta_1 = tmin) %>% 
  mutate(log_b0xb1 = log(beta_0*beta_1)) %>% 
  select(r.squared, log_b0xb1)

boot_strap
```

    ## # A tibble: 5,000 x 2
    ##    r.squared log_b0xb1
    ##        <dbl>     <dbl>
    ##  1     0.912      2.00
    ##  2     0.916      1.98
    ##  3     0.916      1.99
    ##  4     0.901      1.99
    ##  5     0.919      2.00
    ##  6     0.911      2.01
    ##  7     0.920      1.99
    ##  8     0.910      2.01
    ##  9     0.911      1.99
    ## 10     0.906      2.03
    ## # … with 4,990 more rows

We now have our bootstrap samples of R-squared values and logs of the
product of Beta0 and Beta1. Now we can generate a density plot for the
values and products.

``` r
boot_strap %>% 
    ggplot(aes(x = r.squared)) + 
    geom_density(fill = "lightgreen", show.legend = FALSE) +
    geom_vline(xintercept = 0.913, color = "red", size = 1, linetype = 2) +
    labs(
        title = "Distribution of" ~R^2,
        subtitle = "Based on 5000 bootstrap samples of a linear model (tmax ~ tmin)",
        x = quote(R^2)
    )
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/density plot of r.squared values-1.png" style="display: block; margin: auto;" />

We can see from the R-squared density plot that there is a high density
of R-squared values crowded around a center of R = \~0.913. As we recall
from our introductory stats course(s), an R-Squared value falls between
0 and 1, and tells us how much of the variation in `y` can be explained
by `x`. In this case, a vast majority of the variation in `tmax` is
explained by `tmin`.

The 95% confidence interval of `R-squared` is (0.89, 0.93).

``` r
boot_strap %>% 
    ggplot(aes(x = log_b0xb1)) +
    geom_density(fill = "cornflowerblue", show.legend = FALSE) +
    geom_vline(xintercept = 2.012, color = "orange4", size = 1, linetype = 2) +
    labs(
        title = "Distribution of" ~log(hat(beta)[0] %*% hat(beta)[1]),
        subtitle = "Based on 5000 bootstrap samples of a linear model (tmax ~ tmin)",
        x = quote(log(hat(beta)[0] %*% hat(beta)[1]))
    )
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/density plot of log(beta0*beta1)-1.png" style="display: block; margin: auto;" />

As for the density plot of `log(beta_0 x beta_1)`, we see that the
distribution is normal, and centered around a `log(beta_0 x beta_1)`
value of \~2.012.

The 95% confidence interval of `log(beta_0 x beta_1)` is (1.96, 2.06).

-----

## Return of the Bonus Content

<center>

![](bonus_graph.png)

</center>

**h/t:[Toward Data
Science](https://towardsdatascience.com/10-tips-to-improve-your-plotting-f346fa468d18)**
