Data Science - Homework \#6
================
Jon Brock - JPB2210

  - [Problem \#1](#problem-1)
  - [Problem \#2](#problem-2)
  - [Return of the Bonus Content](#return-of-the-bonus-content)

``` r
library(tidyverse)
library(modelr)
```

-----

## Problem \#1

###### (*45 points*)

##### *Working with linear models*

I reviewed each vector to determine what vector type each one should be
when imported. There is a majority of integer values, so the `.default`
value for non-specified vectors applies as such. I specified `babysex`,
`frace`, `malform`, and `mrace` as `<fct>` vectors; `gaweeks`, `ppbmi`,
and `smoken` are specified as `<dbl>` vectors. I will further
tidy–relevel and relabel–my specified `<fct>` vectors in subsequent
code.

``` r
bw_df <- read_csv("./data/birthweight.csv",
                  col_names = TRUE,
                  col_types = cols(
                      .default = col_integer(),
                      babysex = col_factor(),
                      frace = col_factor(),
                      gaweeks = col_double(),
                      malform = col_factor(),
                      mrace = col_factor(),
                      ppbmi = col_double(),
                      smoken = col_double()
                      )
                  )

bw_df
```

    ## # A tibble: 4,342 x 20
    ##    babysex bhead blength   bwt delwt fincome frace gaweeks malform menarche
    ##    <fct>   <int>   <int> <int> <int>   <int> <fct>   <dbl> <fct>      <int>
    ##  1 2          34      51  3629   177      35 1        39.9 0             13
    ##  2 1          34      48  3062   156      65 2        25.9 0             14
    ##  3 2          36      50  3345   148      85 1        39.9 0             12
    ##  4 1          34      52  3062   157      55 1        40   0             14
    ##  5 2          34      52  3374   156       5 1        41.6 0             13
    ##  6 1          33      52  3374   129      55 1        40.7 0             12
    ##  7 2          33      46  2523   126      96 2        40.3 0             14
    ##  8 2          33      49  2778   140       5 1        37.4 0             12
    ##  9 1          36      52  3515   146      85 1        40.3 0             11
    ## 10 1          33      50  3459   169      75 2        40.7 0             12
    ## # … with 4,332 more rows, and 10 more variables: mheight <int>,
    ## #   momage <int>, mrace <fct>, parity <int>, pnumlbw <int>, pnumsga <int>,
    ## #   ppbmi <dbl>, ppwt <int>, smoken <dbl>, wtgain <int>

It is rather tedious to check for `NA` values within individual vectors
one at a time. So, instead, I decided to check all vectors at once by
using a “soft-deprecated” `dplyr` function (`funs()`) to summarize all
of the `NA` observations within each vector in my data frame.

``` r
options(tibble.width = Inf)

bw_df %>% 
    select(everything()) %>% 
    summarize_all(funs(sum(is.na(.))))
```

    ## # A tibble: 1 x 20
    ##   babysex bhead blength   bwt delwt fincome frace gaweeks malform menarche
    ##     <int> <int>   <int> <int> <int>   <int> <int>   <int>   <int>    <int>
    ## 1       0     0       0     0     0       0     0       0       0        0
    ##   mheight momage mrace parity pnumlbw pnumsga ppbmi  ppwt smoken wtgain
    ##     <int>  <int> <int>  <int>   <int>   <int> <int> <int>  <int>  <int>
    ## 1       0      0     0      0       0       0     0     0      0      0

The output shows that we have `0` observations of `NA` in all of our
vectors. We’re good to go\!

``` r
bw_df <- 
    bw_df %>% 
    mutate(
        baby_sex = recode(babysex, "1" = "male", "2" = "female"),
        baby_head_cm = bhead,
        baby_length_cm = blength,
        baby_birthweight_grams = bwt,
        mother_weight_grams = delwt * 453.492,
        family_income = fincome,
        father_race = recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "p_rican", "8" = "other", "9" = "unknown"),
        gestation_age_wks = gaweeks,
        malformations_present = recode(malform, "0" = "absent", "1" = "present"),
        mother_menarche_age = menarche,
        mother_height_cm = mheight * 2.54,
        mother_delivery_age = momage,
        mother_race = recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "p_rican", "8" = "other"),
        number_prior_births = parity,
        number_prior_low_bwt_babies = pnumlbw,
        number_prior_small_ga_babies = pnumsga,
        mother_pre_pregnancy_bmi = ppbmi,
        mother_pre_pregnancy_weight_grams = ppwt * 453.492,
        avg_number_cigs_per_day = smoken,
        mother_pregnancy_weight_gain_grams = wtgain * 453.492) %>% 
    select(c(baby_sex:mother_pregnancy_weight_gain_grams))

colnames(bw_df)
```

    ##  [1] "baby_sex"                          
    ##  [2] "baby_head_cm"                      
    ##  [3] "baby_length_cm"                    
    ##  [4] "baby_birthweight_grams"            
    ##  [5] "mother_weight_grams"               
    ##  [6] "family_income"                     
    ##  [7] "father_race"                       
    ##  [8] "gestation_age_wks"                 
    ##  [9] "malformations_present"             
    ## [10] "mother_menarche_age"               
    ## [11] "mother_height_cm"                  
    ## [12] "mother_delivery_age"               
    ## [13] "mother_race"                       
    ## [14] "number_prior_births"               
    ## [15] "number_prior_low_bwt_babies"       
    ## [16] "number_prior_small_ga_babies"      
    ## [17] "mother_pre_pregnancy_bmi"          
    ## [18] "mother_pre_pregnancy_weight_grams" 
    ## [19] "avg_number_cigs_per_day"           
    ## [20] "mother_pregnancy_weight_gain_grams"

We have successfully recoded and renamed all `20` of our variables, and
dropped the original `20` for lack of further need. It’s important to
note that variable measurements were incongruent in terms of scale –
both metric and imperial were used. To correct for this I made the
necessary conversions so that all measurements are metric (i.e., weight
= grams, height/length = centimeters).

``` r
jon_fit <- lm(baby_birthweight_grams ~ 
                  gestation_age_wks +
                  mother_weight_grams +
                  number_prior_low_bwt_babies +
                  avg_number_cigs_per_day,
              data = bw_df)

broom::tidy(jon_fit) %>% 
    knitr::kable()
```

| term                        |      estimate |  std.error |  statistic |   p.value |
| :-------------------------- | ------------: | ---------: | ---------: | --------: |
| (Intercept)                 | \-145.8454947 | 91.7888378 | \-1.588924 | 0.1121504 |
| gestation\_age\_wks         |    62.5747139 |  2.1709484 |  28.823676 | 0.0000000 |
| mother\_weight\_grams       |     0.0124554 |  0.0006804 |  18.307006 | 0.0000000 |
| avg\_number\_cigs\_per\_day |   \-7.0170283 |  0.9184265 | \-7.640272 | 0.0000000 |

``` r
bw_df %>% 
    add_predictions(jon_fit) %>% 
    add_residuals(jon_fit) %>% 
    ggplot(aes(x = gestation_age_wks, y = baby_birthweight_grams)) + 
        geom_point() + 
        stat_smooth(method = "lm")
```

    ## `geom_smooth()` using formula 'y ~ x'

<img src="p8105_hw6_jpb2210_files/figure-gfm/plotting of model, predictions, and residuals-1.png" style="display: block; margin: auto;" />

``` r
        #geom_line(aes(y = pred), color = "red")
```

-----

## Problem \#2

###### (*35 points*)

##### *Bootstrapping*

This problem focuses on bootstrapping. First, we import a dataset from
NOAA that contains the `minimum` and `maximum` temperatures for Central
Park, NY from the time period 2017-01-10 through 2017-12-31.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_df
```

    ## # A tibble: 365 x 6
    ##    name           id          date        prcp  tmax  tmin
    ##    <chr>          <chr>       <date>     <dbl> <dbl> <dbl>
    ##  1 CentralPark_NY USW00094728 2017-01-01     0   8.9   4.4
    ##  2 CentralPark_NY USW00094728 2017-01-02    53   5     2.8
    ##  3 CentralPark_NY USW00094728 2017-01-03   147   6.1   3.9
    ##  4 CentralPark_NY USW00094728 2017-01-04     0  11.1   1.1
    ##  5 CentralPark_NY USW00094728 2017-01-05     0   1.1  -2.7
    ##  6 CentralPark_NY USW00094728 2017-01-06    13   0.6  -3.8
    ##  7 CentralPark_NY USW00094728 2017-01-07    81  -3.2  -6.6
    ##  8 CentralPark_NY USW00094728 2017-01-08     0  -3.8  -8.8
    ##  9 CentralPark_NY USW00094728 2017-01-09     0  -4.9  -9.9
    ## 10 CentralPark_NY USW00094728 2017-01-10     0   7.8  -6  
    ## # … with 355 more rows

Now we will generate 5000 bootstrap samples from the `weather_df` data
frame, and fit a simple linear regression with `tmax` as the response
and `tmin` as the predictor for each of the 5000 samples. We only want
to look at the distribution of the R-squared value, as well as the log
of the product of Beta0 and Beta1, so we will remove all other items in
the resulting data frame.

``` r
set.seed(90210) #See what I did there?

boot_strap <- 
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    tidy_models = map(models, broom::tidy),
    glance_models = map(models, broom::glance)) %>% 
  unnest(tidy_models, glance_models) %>% 
  select(.id, term, estimate, r.squared) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate) %>% 
  rename(
    beta_0 = `(Intercept)`,
    beta_1 = tmin) %>% 
  mutate(log_b0xb1 = log(beta_0*beta_1)) %>% 
  select(r.squared, log_b0xb1)

boot_strap
```

    ## # A tibble: 5,000 x 2
    ##    r.squared log_b0xb1
    ##        <dbl>     <dbl>
    ##  1     0.912      2.00
    ##  2     0.916      1.98
    ##  3     0.916      1.99
    ##  4     0.901      1.99
    ##  5     0.919      2.00
    ##  6     0.911      2.01
    ##  7     0.920      1.99
    ##  8     0.910      2.01
    ##  9     0.911      1.99
    ## 10     0.906      2.03
    ## # … with 4,990 more rows

We now have our bootstrap samples of R-squared values and logs of the
product of Beta0 and Beta1. Now we can generate a density plot for the
values and products.

``` r
boot_strap %>% 
    ggplot(aes(x = r.squared)) + 
    geom_density(fill = "lightgreen", show.legend = FALSE) +
    labs(
        title = "Distribution of" ~R^2,
        subtitle = "Based on 5000 bootstrap samples of a linear model (tmax ~ tmin)",
        x = quote(R^2)
    )
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/density plot of r.squared values-1.png" style="display: block; margin: auto;" />

We can see from the R-squared density plot that there is a high density
of R-squared values crowded around a center of R = \~0.91. As we recall
from our introductory stats course(s), an R-Squared value falls between
0 and 1, and tells us how much of the variation in `y` can be explained
by `x`. In this case, a vast majority of the variation in `tmax` is
explained by `tmin`.

The 95% confidence interval of `R-squared` is (0.89, 0.93).

``` r
boot_strap %>% 
    ggplot(aes(x = log_b0xb1)) +
    geom_density(fill = "cornflowerblue", show.legend = FALSE) +
    labs(
        title = "Distribution of" ~log(hat(beta)[0] %*% hat(beta)[1]),
        subtitle = "Based on 5000 bootstrap samples of a linear model (tmax ~ tmin)",
        x = quote(log(hat(beta)[0] %*% hat(beta)[1]))
    )
```

<img src="p8105_hw6_jpb2210_files/figure-gfm/density plot of log(beta0*beta1)-1.png" style="display: block; margin: auto;" />

As for the density plot of `log(beta_0 x beta_1)`, we see that the
distribution is normal, and centered around a `log(beta_0 x beta_1)`
value of \~2.025.

The 95% confidence interval of `log(beta_0 x beta_1)` is (1.96, 2.06).

-----

## Return of the Bonus Content

<center>

![](bonus_graph.png)

</center>

**h/t:[Toward Data
Science](https://towardsdatascience.com/10-tips-to-improve-your-plotting-f346fa468d18)**
